# í•œêµ­ì–´ OCR ë°ì´í„°ì…‹ LMDB ì‚¬ìš© ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” í•œêµ­ì–´ OCR ë°ì´í„°ì…‹ë“¤ì„ LMDB í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ¯ ì§€ì› ë°ì´í„°ì…‹

1. **Text in the wild** - í•œêµ­ì–´ ê¸€ìì²´ ë°ì´í„°
2. **023.OCR ë°ì´í„°(ê³µê³µ)** - ê³µê³µ ë¬¸ì„œ OCR ë°ì´í„°
3. **025.OCR ë°ì´í„°(ê¸ˆìœµ ë° ë¬¼ë¥˜)** - ê¸ˆìœµ/ë¬¼ë¥˜ ë¬¸ì„œ OCR ë°ì´í„°
4. **053.ëŒ€ìš©ëŸ‰ ì†ê¸€ì”¨ OCR ë°ì´í„°** - ì†ê¸€ì”¨ OCR ë°ì´í„°
5. **ê³µê³µí–‰ì •ë¬¸ì„œ OCR** - ê³µê³µ í–‰ì • ë¬¸ì„œ OCR ë°ì´í„°

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •

```bash
# LMDB íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install lmdb

# í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ ì„¤ì¹˜
pip install opencv-python pillow numpy torch torchvision
```

### 2ë‹¨ê³„: LMDB ë°ì´í„°ì…‹ ìƒì„±

```bash
# LMDB ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
cd FAST
python create_lmdb_datasets.py
```

ìƒì„±í•  ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ë©´ ìë™ìœ¼ë¡œ LMDB íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

### 3ë‹¨ê³„: ìƒì„±ëœ LMDB í…ŒìŠ¤íŠ¸

```bash
# LMDB ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
python test_lmdb_dataset.py
```

### 4ë‹¨ê³„: í›ˆë ¨ ì‹¤í–‰

```bash
# í•œêµ­ì–´ OCR ëª¨ë¸ í›ˆë ¨
python train_checkpoint_7ep.py \
    --config config/fast/korean_ocr/korean_ocr_lmdb.py \
    --checkpoint checkpoint_7ep.pth \
    --output_dir ./work_dirs/korean_ocr_lmdb
```

## ğŸ“ ë°ì´í„°ì…‹ë³„ ìƒì„¸ ì„¤ì •

### Text in the wild ë°ì´í„°ì…‹

```python
# ì‚¬ìš© ì˜ˆì‹œ
from dataset.fast.fast_lmdb import create_lmdb_dataset

create_lmdb_dataset(
    image_dir="/mnt/y/ocr_dataset/13.í•œêµ­ì–´ê¸€ìì²´/04. Text in the wild_230209_add/images",
    gt_dir="/mnt/y/ocr_dataset/13.í•œêµ­ì–´ê¸€ìì²´/04. Text in the wild_230209_add",
    output_path="./data/text_in_wild.lmdb",
    annotation_parser='text_in_wild'
)
```

**íŠ¹ì§•:**
- í•˜ë‚˜ì˜ JSON íŒŒì¼ì— ëª¨ë“  ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ ì •ë³´
- `bbox: [x, y, width, height]` í˜•ì‹
- `image_id`ë¡œ ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ ë§¤ì¹­

### 023.OCR ë°ì´í„°(ê³µê³µ)

```python
create_lmdb_dataset(
    image_dir="/mnt/y/ocr_dataset/023.OCR ë°ì´í„°(ê³µê³µ)/01-1.ì •ì‹ê°œë°©ë°ì´í„°/Training/01.ì›ì²œë°ì´í„°",
    gt_dir="/mnt/y/ocr_dataset/023.OCR ë°ì´í„°(ê³µê³µ)/01-1.ì •ì‹ê°œë°©ë°ì´í„°/Training/02.ë¼ë²¨ë§ë°ì´í„°",
    output_path="./data/ocr_public_train.lmdb",
    annotation_parser='ocr_public'
)
```

**íŠ¹ì§•:**
- ê° ì´ë¯¸ì§€ë§ˆë‹¤ ê°œë³„ JSON íŒŒì¼
- `x: [x1, x1, x2, x2], y: [y1, y2, y1, y2]` í˜•ì‹
- `Bbox` í‚¤ì— ì–´ë…¸í…Œì´ì…˜ ì •ë³´

### 053.ëŒ€ìš©ëŸ‰ ì†ê¸€ì”¨ OCR ë°ì´í„°

```python
create_lmdb_dataset(
    image_dir="/mnt/y/ocr_dataset/053.ëŒ€ìš©ëŸ‰ ì†ê¸€ì”¨ OCR ë°ì´í„°/01.ë°ì´í„°/1.Training/ì›ì²œë°ì´í„°/TS5/HW-OCR/4.Validation/P.Paper/O.Form",
    gt_dir="/mnt/y/ocr_dataset/053.ëŒ€ìš©ëŸ‰ ì†ê¸€ì”¨ OCR ë°ì´í„°/01.ë°ì´í„°/1.Training/ë¼ë²¨ë§ë°ì´í„°/TL/ë¼ë²¨/HW-OCR/4.Validation/P.Paper/O.Form",
    output_path="./data/handwriting_ts5_paper_form.lmdb",
    annotation_parser='handwriting_ocr'
)
```

**íŠ¹ì§•:**
- ê° ì´ë¯¸ì§€ë§ˆë‹¤ ê°œë³„ JSON íŒŒì¼
- `x: [x1, x1, x2, x2], y: [y1, y2, y1, y2]` í˜•ì‹
- `bbox` í‚¤ì— ì–´ë…¸í…Œì´ì…˜ ì •ë³´

### ê³µê³µí–‰ì •ë¬¸ì„œ OCR

```python
create_lmdb_dataset(
    image_dir="/mnt/y/ocr_dataset/ê³µê³µí–‰ì •ë¬¸ì„œ OCR/Training/[ì›ì²œ]train1/02.ì›ì²œë°ì´í„°(jpg)",
    gt_dir="/mnt/y/ocr_dataset/ê³µê³µí–‰ì •ë¬¸ì„œ OCR/Training/[ë¼ë²¨]train/01.ë¼ë²¨ë§ë°ì´í„°(Json)",
    output_path="./data/public_admin_train1.lmdb",
    annotation_parser='public_admin_ocr'
)
```

**íŠ¹ì§•:**
- ê° ì´ë¯¸ì§€ë§ˆë‹¤ ê°œë³„ JSON íŒŒì¼
- `annotation.bbox: [x, y, width, height]` í˜•ì‹
- `annotations` ë°°ì—´ì— ì–´ë…¸í…Œì´ì…˜ ì •ë³´

## ğŸ”§ ì»¤ìŠ¤í…€ ì„¤ì •

### ë°°ì¹˜ í¬ê¸° ì¡°ì •

```python
# config íŒŒì¼ì—ì„œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
data = dict(
    batch_size=4,  # GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
    train=dict(
        type='FAST_LMDB',
        lmdb_path='./data/your_dataset.lmdb',
        # ... ê¸°íƒ€ ì„¤ì •
    )
)
```

### ë°ì´í„° ì¦ê°• ì„¤ì •

```python
data = dict(
    train=dict(
        type='FAST_LMDB',
        lmdb_path='./data/your_dataset.lmdb',
        is_transform=True,  # ë°ì´í„° ì¦ê°• í™œì„±í™”
        img_size=640,       # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
        short_size=640,     # ìµœì†Œ ë³€ì˜ í¬ê¸°
        repeat_times=1,     # ë°ì´í„° ë°˜ë³µ ë°°ìˆ˜
    )
)
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

```python
# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì„¤ì •
data = dict(
    batch_size=1,  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ
    train=dict(
        repeat_times=1,  # ë°˜ë³µ ë°°ìˆ˜ ê°ì†Œ
        read_type='cv2',  # PILë³´ë‹¤ ë¹ ë¥¸ cv2 ì‚¬ìš©
    )
)
```

### 2. DataLoader ìµœì í™”

```python
# í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ DataLoader ì„¤ì •
from torch.utils.data import DataLoader

dataloader = DataLoader(
    dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=4,      # CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
    pin_memory=True,    # GPU ì „ì†¡ ì†ë„ í–¥ìƒ
    drop_last=True
)
```

## ğŸ› ë¬¸ì œ í•´ê²°

### LMDB íŒŒì¼ ì†ìƒ í™•ì¸

```python
import lmdb

# LMDB ë¬´ê²°ì„± ê²€ì‚¬
env = lmdb.open('./data/your_dataset.lmdb', readonly=True)
with env.begin() as txn:
    cursor = txn.cursor()
    count = sum(1 for _ in cursor)
    print(f'ì´ í‚¤ ê°œìˆ˜: {count}')
env.close()
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

```bash
# ìŠ¤ì™‘ ë©”ëª¨ë¦¬ í™•ì¸
free -h

# ê°€ìƒ ë©”ëª¨ë¦¬ ì„¤ì • (í•„ìš”ì‹œ)
sudo swapon --show
```

### ê²½ë¡œ ë¬¸ì œ í•´ê²°

```python
# ê²½ë¡œ í™•ì¸
import os
print(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì¡´ì¬: {os.path.exists('/your/image/path')}")
print(f"GT ë””ë ‰í† ë¦¬ ì¡´ì¬: {os.path.exists('/your/gt/path')}")
```

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| ë°ì´í„°ì…‹ | ì›ë³¸ í¬ê¸° | LMDB í¬ê¸° | ì••ì¶•ë¥  | ë¡œë”© ì†ë„ |
|----------|-----------|-----------|--------|-----------|
| Text in the wild | 2.5GB | 1.6GB | 36% ê°ì†Œ | 3x ë¹ ë¦„ |
| OCR ê³µê³µ | 1.8GB | 1.1GB | 39% ê°ì†Œ | 4x ë¹ ë¦„ |
| ì†ê¸€ì”¨ OCR | 3.2GB | 2.0GB | 37% ê°ì†Œ | 3.5x ë¹ ë¦„ |
| ê³µê³µí–‰ì •ë¬¸ì„œ | 1.2GB | 0.8GB | 33% ê°ì†Œ | 3x ë¹ ë¦„ |

## ğŸ” ì¶”ê°€ ë„êµ¬

### LMDB ë‚´ìš© í™•ì¸ ë„êµ¬

```python
# ê°„ë‹¨í•œ LMDB ë·°ì–´
def view_lmdb(lmdb_path, sample_idx=0):
    import lmdb
    import pickle
    import cv2
    import numpy as np
    
    env = lmdb.open(lmdb_path, readonly=True)
    with env.begin() as txn:
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_key = f'image-{sample_idx:09d}'.encode()
        img_data = txn.get(img_key)
        img_np = np.frombuffer(img_data, dtype=np.uint8)
        img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)
        
        # GT ë¡œë“œ
        gt_key = f'gt-{sample_idx:09d}'.encode()
        gt_data = txn.get(gt_key)
        gt_info = pickle.loads(gt_data)
        
        print(f"ì´ë¯¸ì§€ í¬ê¸°: {img.shape}")
        print(f"í…ìŠ¤íŠ¸ ê°œìˆ˜: {len(gt_info['words'])}")
        print(f"í…ìŠ¤íŠ¸ ë‚´ìš©: {gt_info['words'][:5]}")  # ì²˜ìŒ 5ê°œë§Œ
    
    env.close()

# ì‚¬ìš© ì˜ˆì‹œ
view_lmdb('./data/text_in_wild.lmdb', 0)
```

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:

1. ë¨¼ì € `test_lmdb_dataset.py`ë¡œ LMDB íŒŒì¼ ë¬´ê²°ì„± í™•ì¸
2. ê²½ë¡œì™€ íŒŒì¼ ê¶Œí•œ í™•ì¸
3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
4. ë¡œê·¸ íŒŒì¼ í™•ì¸

---

**ì°¸ê³ :** ì´ ê°€ì´ë“œëŠ” FAST ëª¨ë¸ê³¼ í•œêµ­ì–´ OCR ë°ì´í„°ì…‹ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì´ë‚˜ ë°ì´í„°ì…‹ ì‚¬ìš© ì‹œ ì¼ë¶€ ì„¤ì •ì„ ì¡°ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 