#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
FAST ëª¨ë¸ íŒŒì¸íŠœë‹ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
checkpoint_7ep.pthë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ë°ì´í„°ì— íŒŒì¸íŠœë‹
"""

import os
import sys
import time
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# FAST ê´€ë ¨ import
sys.path.append('/home/mango/ocr_test/FAST')
from mmcv import Config
from models import build_model
from models.utils import rep_model_convert, fuse_module
from dataset import build_data_loader


class FastTrainer:
    def __init__(self, config_path, checkpoint_path, output_dir='./checkpoints'):
        """
        FAST í›ˆë ¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
            checkpoint_path (str): ì‚¬ì „ í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            output_dir (str): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.config_path = config_path
        self.checkpoint_path = checkpoint_path
        self.output_dir = output_dir
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ì„¤ì • ë¡œë“œ
        self.cfg = Config.fromfile(config_path)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = None
        self.optimizer = None
        self.scheduler = None
        self.start_epoch = 0
        
        print(f"ğŸš€ FAST í›ˆë ¨ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ì„¤ì • íŒŒì¼: {config_path}")
        print(f"   - ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
        print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        print(f"   - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def build_model(self):
        """ëª¨ë¸ êµ¬ì„± ë° ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        print("ğŸ”§ ëª¨ë¸ êµ¬ì„± ì¤‘...")
        
        # ëª¨ë¸ ìƒì„±
        self.model = build_model(self.cfg.model)
        self.model = self.model.to(self.device)
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        if os.path.isfile(self.checkpoint_path):
            print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {self.checkpoint_path}")
            checkpoint = torch.load(self.checkpoint_path, map_location=self.device)
            
            # state_dict ì¶”ì¶œ
            if 'ema' in checkpoint:
                state_dict = checkpoint['ema']
                print("   - EMA ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
                print("   - ì¼ë°˜ ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            else:
                state_dict = checkpoint
                print("   - ì§ì ‘ ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            
            # ì—í¬í¬ ì •ë³´ ì¶”ì¶œ
            if 'epoch' in checkpoint:
                self.start_epoch = checkpoint['epoch']
                print(f"   - ì‹œì‘ ì—í¬í¬: {self.start_epoch}")
            
            # í‚¤ì—ì„œ 'module.' ì œê±°
            new_state_dict = {}
            for key, value in state_dict.items():
                new_key = key.replace("module.", "")
                new_state_dict[new_key] = value
            
            # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ
            missing_keys, unexpected_keys = self.model.load_state_dict(new_state_dict, strict=False)
            
            if missing_keys:
                print(f"   âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
            if unexpected_keys:
                print(f"   âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
            
            print("âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
        else:
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.checkpoint_path}")
        
        # í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •
        self.model.train()
        
    def build_optimizer(self):
        """ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬ì„±"""
        print("ğŸ”§ ì˜µí‹°ë§ˆì´ì € êµ¬ì„± ì¤‘...")
        
        # í•™ìŠµë¥  ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        lr = getattr(self.cfg.train_cfg, 'lr', 1e-3)
        optimizer_type = getattr(self.cfg.train_cfg, 'optimizer', 'Adam')
        
        if optimizer_type == 'Adam':
            self.optimizer = optim.Adam(self.model.parameters(), lr=lr)
        elif optimizer_type == 'SGD':
            self.optimizer = optim.SGD(
                self.model.parameters(), 
                lr=lr, 
                momentum=0.9, 
                weight_decay=1e-4
            )
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜µí‹°ë§ˆì´ì €: {optimizer_type}")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        schedule_type = getattr(self.cfg.train_cfg, 'schedule', 'polylr')
        if schedule_type == 'polylr':
            # Polynomial learning rate decay
            total_epochs = getattr(self.cfg.train_cfg, 'epoch', 100)
            self.scheduler = optim.lr_scheduler.PolynomialLR(
                self.optimizer, 
                total_iters=total_epochs,
                power=0.9
            )
        else:
            # ê¸°ë³¸ ìŠ¤ì¼€ì¤„ëŸ¬
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer, 
                step_size=30, 
                gamma=0.1
            )
        
        print(f"   - ì˜µí‹°ë§ˆì´ì €: {optimizer_type}")
        print(f"   - ì´ˆê¸° í•™ìŠµë¥ : {lr}")
        print(f"   - ìŠ¤ì¼€ì¤„ëŸ¬: {schedule_type}")
        print("âœ… ì˜µí‹°ë§ˆì´ì € êµ¬ì„± ì™„ë£Œ")
    
    def build_dataloader(self):
        """ë°ì´í„°ë¡œë” êµ¬ì„±"""
        print("ğŸ”§ ë°ì´í„°ë¡œë” êµ¬ì„± ì¤‘...")
        
        # í›ˆë ¨ ë°ì´í„°ë¡œë”
        train_dataset = build_data_loader(self.cfg.data.train)
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=getattr(self.cfg.data, 'batch_size', 4),
            shuffle=True,
            num_workers=4,
            pin_memory=True,
            drop_last=True
        )
        
        print(f"   - ë°°ì¹˜ í¬ê¸°: {getattr(self.cfg.data, 'batch_size', 4)}")
        print(f"   - í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(train_dataset)}")
        print(f"   - ë°°ì¹˜ ìˆ˜: {len(self.train_loader)}")
        print("âœ… ë°ì´í„°ë¡œë” êµ¬ì„± ì™„ë£Œ")
    
    def train_epoch(self, epoch):
        """í•œ ì—í¬í¬ í›ˆë ¨"""
        self.model.train()
        total_loss = 0.0
        total_loss_text = 0.0
        total_loss_kernel = 0.0
        total_loss_emb = 0.0
        
        print(f"\nğŸ“š ì—í¬í¬ {epoch+1} í›ˆë ¨ ì‹œì‘...")
        start_time = time.time()
        
        for batch_idx, batch in enumerate(self.train_loader):
            # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
            imgs = batch['imgs'].to(self.device)
            gt_texts = batch['gt_texts'].to(self.device)
            gt_kernels = batch['gt_kernels'].to(self.device)
            training_masks = batch['training_masks'].to(self.device)
            gt_instances = batch['gt_instances'].to(self.device)
            
            # ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
            self.optimizer.zero_grad()
            
            # ìˆœë°©í–¥ íŒ¨ìŠ¤
            outputs = self.model(
                imgs=imgs,
                gt_texts=gt_texts,
                gt_kernels=gt_kernels,
                training_masks=training_masks,
                gt_instances=gt_instances
            )
            
            # ì†ì‹¤ ê³„ì‚°
            loss_text = outputs['loss_text'].mean()
            loss_kernels = outputs['loss_kernels'].mean()
            loss_emb = outputs['loss_emb'].mean()
            
            total_loss_batch = loss_text + loss_kernels + loss_emb
            
            # ì—­ë°©í–¥ íŒ¨ìŠ¤
            total_loss_batch.backward()
            self.optimizer.step()
            
            # ì†ì‹¤ ëˆ„ì 
            total_loss += total_loss_batch.item()
            total_loss_text += loss_text.item()
            total_loss_kernel += loss_kernels.item()
            total_loss_emb += loss_emb.item()
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if (batch_idx + 1) % 10 == 0:
                avg_loss = total_loss / (batch_idx + 1)
                print(f"   ë°°ì¹˜ [{batch_idx+1}/{len(self.train_loader)}] "
                      f"Loss: {total_loss_batch.item():.4f} "
                      f"(Avg: {avg_loss:.4f}) "
                      f"Text: {loss_text.item():.4f} "
                      f"Kernel: {loss_kernels.item():.4f} "
                      f"Emb: {loss_emb.item():.4f}")
        
        # ì—í¬í¬ í†µê³„
        epoch_time = time.time() - start_time
        avg_loss = total_loss / len(self.train_loader)
        avg_loss_text = total_loss_text / len(self.train_loader)
        avg_loss_kernel = total_loss_kernel / len(self.train_loader)
        avg_loss_emb = total_loss_emb / len(self.train_loader)
        
        print(f"ğŸ“Š ì—í¬í¬ {epoch+1} ì™„ë£Œ ({epoch_time:.1f}ì´ˆ)")
        print(f"   - í‰ê·  ì´ ì†ì‹¤: {avg_loss:.4f}")
        print(f"   - í‰ê·  í…ìŠ¤íŠ¸ ì†ì‹¤: {avg_loss_text:.4f}")
        print(f"   - í‰ê·  ì»¤ë„ ì†ì‹¤: {avg_loss_kernel:.4f}")
        print(f"   - í‰ê·  ì„ë² ë”© ì†ì‹¤: {avg_loss_emb:.4f}")
        print(f"   - í•™ìŠµë¥ : {self.optimizer.param_groups[0]['lr']:.6f}")
        
        return avg_loss
    
    def save_checkpoint(self, epoch, loss, is_best=False):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': epoch + 1,
            'state_dict': self.model.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict(),
            'loss': loss,
            'config': self.cfg
        }
        
        # ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        checkpoint_path = os.path.join(self.output_dir, f'checkpoint_epoch_{epoch+1}.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        latest_path = os.path.join(self.output_dir, 'checkpoint_latest.pth')
        torch.save(checkpoint, latest_path)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if is_best:
            best_path = os.path.join(self.output_dir, 'checkpoint_best.pth')
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {best_path}")
        
        print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")
    
    def train(self, num_epochs=None):
        """ì „ì²´ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤"""
        if num_epochs is None:
            num_epochs = getattr(self.cfg.train_cfg, 'epoch', 100)
        
        print(f"ğŸš€ FAST ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        print(f"   - ì´ ì—í¬í¬: {num_epochs}")
        print(f"   - ì‹œì‘ ì—í¬í¬: {self.start_epoch}")
        print("=" * 60)
        
        best_loss = float('inf')
        save_interval = getattr(self.cfg.train_cfg, 'save_interval', 10)
        
        for epoch in range(self.start_epoch, num_epochs):
            # í›ˆë ¨
            avg_loss = self.train_epoch(epoch)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            self.scheduler.step()
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            is_best = avg_loss < best_loss
            if is_best:
                best_loss = avg_loss
            
            # ì£¼ê¸°ì  ì €ì¥ ë˜ëŠ” ìµœê³  ì„±ëŠ¥ì¼ ë•Œ ì €ì¥
            if (epoch + 1) % save_interval == 0 or is_best or (epoch + 1) == num_epochs:
                self.save_checkpoint(epoch, avg_loss, is_best)
        
        print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
        print(f"   - ìµœê³  ì„±ëŠ¥ ì†ì‹¤: {best_loss:.4f}")
        print(f"   - ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")


def main():
    parser = argparse.ArgumentParser(description='FAST ëª¨ë¸ íŒŒì¸íŠœë‹ í›ˆë ¨')
    parser.add_argument('--config', type=str, required=True, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--checkpoint', type=str, default='checkpoint_7ep.pth', help='ì‚¬ì „ í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--output_dir', type=str, default='./finetune_checkpoints', help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--epochs', type=int, default=None, help='í›ˆë ¨ ì—í¬í¬ ìˆ˜')
    parser.add_argument('--gpu', type=str, default='0', help='ì‚¬ìš©í•  GPU ID')
    
    args = parser.parse_args()
    
    # GPU ì„¤ì •
    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu
    
    # í›ˆë ¨ ì‹¤í–‰
    trainer = FastTrainer(
        config_path=args.config,
        checkpoint_path=args.checkpoint,
        output_dir=args.output_dir
    )
    
    # êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    trainer.build_model()
    trainer.build_optimizer()
    trainer.build_dataloader()
    
    # í›ˆë ¨ ì‹œì‘
    trainer.train(num_epochs=args.epochs)


if __name__ == '__main__':
    main() 