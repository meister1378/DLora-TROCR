#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ê¸°ì¡´ lookup .py íŒŒì¼ë“¤ì„ ë¹ ë¥¸ pickle ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
Python import ì˜¤ë²„í—¤ë“œë¥¼ ì œê±°í•˜ì—¬ 5-10ë°° ì„±ëŠ¥ í–¥ìƒ
"""

import os
import sys
import pickle
import gzip
import time
import importlib.util
from pathlib import Path

class LookupConverter:
    """Lookup í•¨ìˆ˜ë¥¼ pickle ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, fast_dir="FAST"):
        self.fast_dir = fast_dir
        self.lookup_files = self._find_lookup_files()
        
    def _find_lookup_files(self):
        """FAST ë””ë ‰í† ë¦¬ì—ì„œ lookup .py íŒŒì¼ë“¤ì„ ì°¾ê¸°"""
        lookup_files = []
        fast_path = Path(self.fast_dir)
        
        if fast_path.exists():
            for py_file in fast_path.glob("optimized_lookup_*.py"):
                if py_file.name != "__pycache__":
                    lookup_files.append(py_file)
        
        return lookup_files
    
    def extract_lookup_dict_from_py(self, py_file_path):
        """Python íŒŒì¼ì—ì„œ direct_mappings ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ"""
        print(f"  ğŸ”„ {py_file_path.name}ì—ì„œ ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ ì¤‘...")
        
        try:
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            with open(py_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # direct_mappings ë”•ì…”ë„ˆë¦¬ ë¶€ë¶„ ì¶”ì¶œ
            start_marker = "direct_mappings = {"
            end_marker = "    }"
            
            start_idx = content.find(start_marker)
            if start_idx == -1:
                print(f"    âš ï¸ direct_mappingsë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return {}
            
            # ë”•ì…”ë„ˆë¦¬ ë ì°¾ê¸° (ì¤‘ê´„í˜¸ ë§¤ì¹­)
            bracket_count = 0
            end_idx = start_idx + len(start_marker)
            
            for i, char in enumerate(content[start_idx + len(start_marker):], start_idx + len(start_marker)):
                if char == '{':
                    bracket_count += 1
                elif char == '}':
                    bracket_count -= 1
                    if bracket_count == -1:  # ë”•ì…”ë„ˆë¦¬ ì¢…ë£Œ
                        end_idx = i + 1
                        break
            
            # ë”•ì…”ë„ˆë¦¬ ë¬¸ìì—´ ì¶”ì¶œ
            dict_str = content[start_idx:end_idx]
            
            # ì•ˆì „í•˜ê²Œ ë”•ì…”ë„ˆë¦¬ ì‹¤í–‰ (eval ëŒ€ì‹  exec ì‚¬ìš©)
            local_vars = {}
            exec(dict_str, {}, local_vars)
            
            direct_mappings = local_vars.get('direct_mappings', {})
            print(f"    âœ… {len(direct_mappings)}ê°œ ë§¤í•‘ ì¶”ì¶œ ì™„ë£Œ")
            
            return direct_mappings
            
        except Exception as e:
            print(f"    âŒ ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    def save_as_pickle(self, lookup_dict, dataset_name, use_compression=True):
        """ë”•ì…”ë„ˆë¦¬ë¥¼ pickle íŒŒì¼ë¡œ ì €ì¥"""
        if use_compression:
            output_file = f"{self.fast_dir}/lookup_{dataset_name}.pkl.gz"
            print(f"  ğŸ’¾ ì••ì¶•ëœ pickleë¡œ ì €ì¥: {output_file}")
            
            with gzip.open(output_file, 'wb') as f:
                pickle.dump(lookup_dict, f, protocol=pickle.HIGHEST_PROTOCOL)
        else:
            output_file = f"{self.fast_dir}/lookup_{dataset_name}.pkl"
            print(f"  ğŸ’¾ pickleë¡œ ì €ì¥: {output_file}")
            
            with open(output_file, 'wb') as f:
                pickle.dump(lookup_dict, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        return output_file
    
    def convert_all(self, use_compression=True):
        """ëª¨ë“  lookup íŒŒì¼ì„ pickleë¡œ ë³€í™˜"""
        print("ğŸš€ Lookup íŒŒì¼ë“¤ì„ pickle ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜")
        print("=" * 60)
        
        if not self.lookup_files:
            print("âŒ lookup .py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print("ğŸ’¡ ë¨¼ì € ftp_tree_viewer.pyë¥¼ ì‹¤í–‰í•´ì„œ lookup í•¨ìˆ˜ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”")
            return
        
        converted_files = []
        total_start_time = time.time()
        
        for py_file in self.lookup_files:
            print(f"\nğŸ“ {py_file.name} ë³€í™˜ ì¤‘...")
            start_time = time.time()
            
            # ë°ì´í„°ì…‹ ì´ë¦„ ì¶”ì¶œ
            dataset_name = py_file.stem.replace("optimized_lookup_", "")
            
            # ë”•ì…”ë„ˆë¦¬ ì¶”ì¶œ
            lookup_dict = self.extract_lookup_dict_from_py(py_file)
            
            if lookup_dict:
                # pickleë¡œ ì €ì¥
                output_file = self.save_as_pickle(lookup_dict, dataset_name, use_compression)
                
                # ì„±ëŠ¥ ë¹„êµ
                original_size = py_file.stat().st_size
                pickle_size = os.path.getsize(output_file)
                
                end_time = time.time()
                print(f"  âœ… ë³€í™˜ ì™„ë£Œ ({end_time - start_time:.3f}ì´ˆ)")
                print(f"     ğŸ“Š í¬ê¸°: {original_size:,} bytes â†’ {pickle_size:,} bytes ({pickle_size/original_size:.1%})")
                
                converted_files.append(output_file)
            else:
                print(f"  âŒ {py_file.name} ë³€í™˜ ì‹¤íŒ¨")
        
        total_time = time.time() - total_start_time
        print(f"\n{'='*60}")
        print(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(converted_files)}ê°œ íŒŒì¼ ({total_time:.2f}ì´ˆ)")
        print(f"ğŸ“ ë³€í™˜ëœ íŒŒì¼ë“¤:")
        for file in converted_files:
            print(f"   - {file}")
        
        return converted_files
    
    def benchmark_loading_speed(self, dataset_name):
        """pickle vs Python import ë¡œë”© ì†ë„ ë¹„êµ"""
        print(f"\nâš¡ {dataset_name} ë¡œë”© ì†ë„ ë²¤ì¹˜ë§ˆí¬")
        print("-" * 40)
        
        # 1. Python import ë°©ì‹
        py_file = f"{self.fast_dir}/optimized_lookup_{dataset_name}.py"
        if os.path.exists(py_file):
            start_time = time.time()
            try:
                spec = importlib.util.spec_from_file_location("lookup_module", py_file)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                lookup_func = getattr(module, f"lookup_{dataset_name}")
                py_time = time.time() - start_time
                print(f"ğŸŒ Python import: {py_time:.4f}ì´ˆ")
            except Exception as e:
                print(f"âŒ Python import ì‹¤íŒ¨: {e}")
                py_time = float('inf')
        else:
            print(f"âš ï¸ Python íŒŒì¼ ì—†ìŒ: {py_file}")
            py_time = float('inf')
        
        # 2. Pickle ë°©ì‹ (ì••ì¶•)
        pkl_gz_file = f"{self.fast_dir}/lookup_{dataset_name}.pkl.gz"
        if os.path.exists(pkl_gz_file):
            start_time = time.time()
            try:
                with gzip.open(pkl_gz_file, 'rb') as f:
                    lookup_dict = pickle.load(f)
                pkl_gz_time = time.time() - start_time
                print(f"âš¡ Pickle (ì••ì¶•): {pkl_gz_time:.4f}ì´ˆ")
                
                # ë”•ì…”ë„ˆë¦¬ í¬ê¸° í™•ì¸
                print(f"   ğŸ“Š ë§¤í•‘ ìˆ˜: {len(lookup_dict):,}ê°œ")
            except Exception as e:
                print(f"âŒ Pickle ë¡œë“œ ì‹¤íŒ¨: {e}")
                pkl_gz_time = float('inf')
        else:
            print(f"âš ï¸ Pickle íŒŒì¼ ì—†ìŒ: {pkl_gz_file}")
            pkl_gz_time = float('inf')
        
        # 3. Pickle ë°©ì‹ (ë¹„ì••ì¶•)
        pkl_file = f"{self.fast_dir}/lookup_{dataset_name}.pkl"
        if os.path.exists(pkl_file):
            start_time = time.time()
            try:
                with open(pkl_file, 'rb') as f:
                    lookup_dict = pickle.load(f)
                pkl_time = time.time() - start_time
                print(f"âš¡ Pickle (ë¹„ì••ì¶•): {pkl_time:.4f}ì´ˆ")
            except Exception as e:
                print(f"âŒ Pickle ë¡œë“œ ì‹¤íŒ¨: {e}")
                pkl_time = float('inf')
        else:
            pkl_time = float('inf')
        
        # ì„±ëŠ¥ ë¹„êµ
        best_time = min(py_time, pkl_gz_time, pkl_time)
        if best_time != float('inf'):
            if py_time != float('inf'):
                speedup = py_time / best_time
                print(f"ğŸš€ ì„±ëŠ¥ í–¥ìƒ: {speedup:.1f}ë°° ë¹ ë¦„!")
            else:
                print(f"ğŸš€ Pickleì´ ìœ ì¼í•œ ì˜µì…˜!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Lookup í•¨ìˆ˜ ìµœì í™”: Python â†’ Pickle ë³€í™˜")
    print("=" * 60)
    
    converter = LookupConverter()
    
    # 1. ëª¨ë“  lookup íŒŒì¼ ë³€í™˜
    converted_files = converter.convert_all(use_compression=True)
    
    if not converted_files:
        return
    
    # 2. ëª‡ ê°œ íŒŒì¼ì— ëŒ€í•´ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    sample_datasets = [
        "ocr_public_train"
    ]
    
    print(f"\n{'='*60}")
    print("âš¡ ë¡œë”© ì†ë„ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 60)
    
    for dataset in sample_datasets:
        if any(dataset in f for f in converted_files):
            converter.benchmark_loading_speed(dataset)
    
    print(f"\n{'='*60}")
    print("âœ… ìµœì í™” ì™„ë£Œ!")
    print("ğŸ’¡ ì´ì œ create_all_datasets_500_clean.pyë¥¼ ìˆ˜ì •í•´ì„œ pickleì„ ì‚¬ìš©í•˜ì„¸ìš”!")

if __name__ == "__main__":
    main() 